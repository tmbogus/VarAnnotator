
# VarAnnotator - Issue Tracker

## Closed Issues

### 1. **HTTPError Handling in EnsemblRestClient**
- Fixed how 404 and 500 errors are raised after retries.
- Mocked `time.sleep` for faster testing of retries in unit tests.

### 2. **Mocking Errors in Tests**
- Improved mocking strategy for `HTTPError` and `urlopen`.
- Fixed issues with mocking headers in error responses.

### 3. **Test Suite Failures**
- Addressed test failures related to `truncate_text`.
- Resolved issues with handling JSON serialization in mock responses.

### 4. **Error Not Raised After Max Retries**
- The `EnsemblRestClient` did not correctly raise an error after max retries for HTTP 500 errors.
- Fixed logic to raise the original error correctly after retry attempts are exhausted.

### 5. **Test for 500 Error in `EnsemblRestClient` Failing**
- Mocked HTTP 500 error was not being properly raised.
- Introduced checks to ensure correct error handling in tests by adjusting retry behavior and adding explicit exception raises.

### 6. **Improper Handling of HTTP 404 in `EnsemblRestClient`**
- Mocked HTTP 404 errors in tests were not being raised due to incorrect attributes in the mock object.
- Corrected the mocking of the `HTTPError` class to properly set attributes like `reason` and `headers`.

### 7. **Handling of Variants with Multiple Alleles in Population Frequency Retrieval**
- The `fetch_population_frequency` function was failing to retrieve the correct frequency when multiple alleles existed.
- Adjusted the logic to ensure correct matching between the VCF alternate allele and the allele provided by the API.

### 8. **Incorrect Handling of Rate Limits**
- The rate-limiting logic was not correctly waiting when encountering HTTP 429 errors, leading to API rate limit breaches.
- Implemented exponential backoff with proper delays based on the `Retry-After` header.

### 9. **Batched API Calls Not Utilized in Tests**
- The test suite did not properly mock or test the batch API functionality.
- Updated test cases to include batched requests, ensuring efficient API utilization and response handling.

### 10. **Parallel API Requests**
- Initial implementation did not fully parallelize the fetching of population frequency, gene annotation, and dbSNP ID.
- Refactored to ensure all tasks are submitted in parallel, improving performance.

---

## Known Issues / Enhancements

### 1. **More Comprehensive Edge Case Testing**
- Add additional test cases for more HTTP error statuses (e.g., 401, 403).
- Ensure robustness across all API interaction scenarios, especially when dealing with complex variants and alternate alleles.

### 2. **Performance Optimizations**
- Explore asynchronous API calls to handle large data requests more efficiently.
- Investigate the use of multiprocessing or async I/O to reduce overall processing time for large VCF files.

### 3. **Improved Documentation**
- Expand the README and API documentation to include detailed usage examples, explanations of retry logic, and error-handling mechanisms.

### 4. **Population Frequency Aggregation**
- Improve how population frequencies are aggregated and presented, ensuring all relevant populations are considered and correctly annotated.

### 5. **Database Support for Variant Storage**
- Introduce support for storing variant annotations in a database, allowing for more scalable access, querying, and filtering of variant data.

### 6. **Support for detection of genome version**
 - Implement the capability of detecting the genome version used in the VCF and use the appropriate API/Endpoints.

### 7. **Local annotation mode**
 - A new mode where database files are downloaded, updated and used for doing dbSNP, gene and population frequency annotation.

### 8. **Cloud infrastructure, platform and software services**
 - Future implementations of the project could leverage a range of cloud services to enhance functionality and scalability. For scalable variant storage, managed databases such as Amazon RDS or Aurora, Google Cloud SQL, and Azure SQL Database might be utilized. Serverless functions like AWS Lambda, Google Cloud Functions, or Azure Functions could be employed to handle genome version detection and automate workflows efficiently. To support both local and cloud-based annotation modes, object storage solutions such as Amazon S3, Google Cloud Storage, or Azure Blob Storage would provide reliable data storage and access. Data warehousing and analytics tools like Amazon Redshift, BigQuery, or Azure Synapse Analytics could facilitate efficient querying and comprehensive data analysis. Additionally, container orchestration platforms such as Amazon EKS, Google Kubernetes Engine (GKE), or Azure Kubernetes Service (AKS) might be used to scale annotation processing seamlessly. API management could be addressed through services like Amazon API Gateway, Google Cloud Endpoints, or Azure API Management, while workflow orchestration could be streamlined using AWS Step Functions, Google Cloud Composer, or Azure Logic Apps. Lastly, adopting Infrastructure as Code (IaC) tools like Terraform would ensure consistent and automated deployment across the chosen cloud environments. This integration of diverse cloud services would provide a robust, scalable, and efficient foundation for the project's future enhancements.

---